# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import json
from fpdf import FPDF
from fpdf.enums import XPos, YPos
import io
from io import BytesIO
import traceback
from pydantic import BaseModel, Field, ValidationError, conlist
from typing import List, Optional
from enum import Enum

# --- CONFIGURATION & CONSTANTES ---
st.set_page_config(page_title="Rapports NDF", layout="wide")

PERIOD_TRANSLATION = {"Day": "par Jour", "None": "par D√©pense", "Month": "par Mois", "Year": "par An"}

class JsonKeys(str, Enum):
    PROFILES = "profiles"
    NATURES = "natures"
    LIMITS = "limits"
    ALLOWANCES = "allowances"
    ID = "id"
    ID_NATURES = "idNatures"
    MULTILINGUAL_NAME = "multilingualName"
    CURRENCY_CODE = "currencyCode"
    THRESHOLDS = "thresholds"
    AMOUNT = "amount"
    TYPE = "type"
    PERIOD = "period"
    CHARTS_OF_ACCOUNTS = "chartsOfAccounts"
    COSTS_ACCOUNTS = "costsAccounts"
    FORMAT = "format"
    VALUE = "value"
    NAME = "name"
    NATURE_ACCOUNT_MAPPINGS = "natureAccountMappings"
    ID_NATURE = "idNature"
    ID_COSTS_ACCOUNT = "idCostsAccount"
    VAT_OPTIONS = "vatOptions"
    ID_COUNTRY_VATS = "idCountryVats"
    FR_FR = "fr-FR"


# --- MOD√àLES PYDANTIC ---
class Threshold(BaseModel):
    amount: Optional[float] = None

class Limit(BaseModel):
    idNatures: List[int] = Field(default_factory=list)
    type: Optional[str] = None
    period: Optional[str] = None
    currencyCode: Optional[str] = None
    thresholds: conlist(Threshold, max_length=1) = Field(default_factory=list)

class Allowance(BaseModel):
    idNatures: List[int] = Field(default_factory=list)
    currencyCode: Optional[str] = None
    thresholds: conlist(Threshold, max_length=1) = Field(default_factory=list)

class Profile(BaseModel):
    id: Optional[int] = None
    multilingualName: dict = Field(default_factory=dict)
    idNatures: List[int] = Field(default_factory=list)
    limits: List[Limit] = Field(default_factory=list)
    allowances: List[Allowance] = Field(default_factory=list)
    
    @property
    def name_fr(self) -> str:
        name = self.multilingualName.get(JsonKeys.FR_FR)
        if name:
            return name
        if self.id is not None:
            return f"Profil sans nom (ID: {self.id})"
        return "Profil non identifi√©"

class Nature(BaseModel):
    id: int
    multilingualName: dict = Field(default_factory=dict)
    
    @property
    def name_fr(self) -> str:
        return self.multilingualName.get(JsonKeys.FR_FR, f"ID {self.id}")

class CostsAccount(BaseModel):
    id: int
    format: conlist(dict, max_length=1) = Field(default_factory=list)
    
    @property
    def value(self) -> str:
        return self.format[0].get(JsonKeys.VALUE, 'N/A') if self.format else 'N/A'

class NatureAccountMapping(BaseModel):
    idNature: int
    idCostsAccount: Optional[int] = None
    vatOptions: dict = Field(default_factory=dict)
    
    @property
    def vat_ids(self) -> List[str]:
        return self.vatOptions.get(JsonKeys.ID_COUNTRY_VATS, [])

class ChartOfAccounts(BaseModel):
    id: int
    name: Optional[str] = None
    costsAccounts: List[CostsAccount] = Field(default_factory=list)
    natureAccountMappings: List[NatureAccountMapping] = Field(default_factory=list)

class CleemyData(BaseModel):
    profiles: List[Profile] = Field(default_factory=list)
    natures: List[Nature] = Field(default_factory=list)
    chartsOfAccounts: List[ChartOfAccounts] = Field(default_factory=list)


# --- FONCTIONS DE TRAITEMENT ET D'AUDIT DES DONN√âES ---
@st.cache_data(hash_funcs={BytesIO: lambda _: None})
def load_and_process_data(uploaded_file: io.BytesIO) -> dict | None:
    """Charge, valide avec Pydantic et pr√©-traite les donn√©es JSON."""
    with st.spinner("Analyse et validation du fichier en cours..."):
        try:
            uploaded_file.seek(0)
            raw_data = json.load(uploaded_file)
            data = CleemyData.model_validate(raw_data)

            nature_lookup = {n.id: n.name_fr for n in data.natures}
            df_profiles = _create_profile_nature_df(data, nature_lookup)
            df_limits = _create_limits_df(data, nature_lookup)
            nature_to_profiles_map = _create_nature_to_profiles_map(data)

            return {
                "pydantic_data": data,
                "nature_lookup": nature_lookup,
                "df_profiles": df_profiles,
                "df_limits": df_limits,
                "nature_to_profiles_map": nature_to_profiles_map,
                "error": None
            }
        except ValidationError as e:
            st.error(f"‚ùå Fichier invalide : la structure des donn√©es est incorrecte.")
            st.code(str(e))
            return {"error": str(e)}
        except Exception as e:
            st.error(f"Une erreur critique est survenue : {e}")
            st.code(traceback.format_exc())
            return {"error": traceback.format_exc()}

def _create_profile_nature_df(data: CleemyData, nature_lookup: dict) -> pd.DataFrame:
    """Cr√©e un DataFrame liant chaque profil aux natures qui lui sont associ√©es."""
    export_data = []
    for profile in data.profiles:
        for id_nature in profile.idNatures:
            export_data.append({
                "Profil": profile.name_fr,
                "ID Nature": id_nature,
                "Nom de la nature": nature_lookup.get(id_nature, "‚ùì Inconnu"),
            })
    return pd.DataFrame(export_data)

def _create_limits_df(data: CleemyData, nature_lookup: dict) -> pd.DataFrame:
    """Cr√©e un DataFrame consolid√© de toutes les limites et indemnit√©s de tous les profils."""
    limits_data = []
    for profile in data.profiles:
        profile_name = profile.name_fr
        for limit in profile.limits:
            nature_names = [nature_lookup.get(nid, f"ID {nid}") for nid in limit.idNatures]
            thresholds = limit.thresholds[0] if limit.thresholds else Threshold()
            limits_data.append({
                "Profil": profile_name, "Type de R√®gle": "Limite",
                "Natures Concern√©es": ", ".join(filter(None, nature_names)),
                "Type de Plafond": getattr(limit, 'type', 'N/A').capitalize(),
                "Montant": thresholds.amount,
                "Devise": limit.currencyCode,
                "P√©riode": PERIOD_TRANSLATION.get(limit.period, limit.period)
            })
        for allowance in profile.allowances:
            nature_names = [nature_lookup.get(nid, f"ID {nid}") for nid in allowance.idNatures]
            thresholds = allowance.thresholds[0] if allowance.thresholds else Threshold()
            limits_data.append({
                "Profil": profile_name, "Type de R√®gle": "Indemnit√©",
                "Natures Concern√©es": ", ".join(filter(None, nature_names)),
                "Type de Plafond": "Forfait",
                "Montant": thresholds.amount,
                "Devise": allowance.currencyCode, "P√©riode": "N/A"
            })
    return pd.DataFrame(limits_data)

def _create_nature_to_profiles_map(data: CleemyData) -> dict:
    """Cr√©e un dictionnaire mappant chaque ID de nature aux profils et r√®gles qui l'utilisent."""
    nature_map = {}
    for profile in data.profiles:
        for nature_id in profile.idNatures:
            nature_map.setdefault(nature_id, {}).setdefault(profile.name_fr, {"limits": [], "allowances": []})
        for limit in profile.limits:
            for nature_id in limit.idNatures:
                profile_rules = nature_map.setdefault(nature_id, {}).setdefault(profile.name_fr, {"limits": [], "allowances": []})
                profile_rules["limits"].append(limit)
        for allowance in profile.allowances:
            for nature_id in allowance.idNatures:
                profile_rules = nature_map.setdefault(nature_id, {}).setdefault(profile.name_fr, {"limits": [], "allowances": []})
                profile_rules["allowances"].append(allowance)
    return nature_map

def find_orphan_nature_ids(df_profiles: pd.DataFrame, nature_lookup: dict) -> set:
    """Trouve les ID de natures utilis√©s dans les profils mais non d√©finis."""
    nature_ids_in_df = set(df_profiles["ID Nature"].unique())
    nature_ids_in_dict = set(nature_lookup.keys())
    orphans = nature_ids_in_df - nature_ids_in_dict
    return orphans

def audit_inconsistent_rules(data: CleemyData, nature_lookup: dict) -> list:
    """Trouve les r√®gles avec des montants nuls ou non d√©finis."""
    warnings = []
    for profile in data.profiles:
        for limit in profile.limits:
            threshold = limit.thresholds[0] if limit.thresholds else Threshold()
            if threshold.amount is None or threshold.amount == 0:
                nature_names = [nature_lookup.get(nid, f"ID {nid}") for nid in limit.idNatures]
                warnings.append(
                    f"**Profil '{profile.name_fr}'** : Limite avec montant nul ou non d√©fini pour : *{', '.join(nature_names)}*."
                )
        for allowance in profile.allowances:
            threshold = allowance.thresholds[0] if allowance.thresholds else Threshold()
            if threshold.amount is None or threshold.amount == 0:
                nature_names = [nature_lookup.get(nid, f"ID {nid}") for nid in allowance.idNatures]
                warnings.append(
                    f"**Profil '{profile.name_fr}'** : Indemnit√© avec montant nul ou non d√©fini pour : *{', '.join(nature_names)}*."
                )
    return warnings


# --- FONCTION D'ASSISTANCE POUR L'AFFICHAGE ---
def display_rule(rule: Limit | Allowance, nature_lookup: dict, show_natures: bool = True):
    """Affiche une r√®gle (Limite ou Indemnit√©) de mani√®re format√©e dans Streamlit."""
    if isinstance(rule, Limit):
        thresholds = rule.thresholds[0] if rule.thresholds else Threshold()
        amount, currency = thresholds.amount, rule.currencyCode
        limit_type = getattr(rule, 'type', 'N/A').capitalize()
        period = PERIOD_TRANSLATION.get(rule.period, rule.period)
        icon, color_func = ("üõë", st.error) if limit_type == "Absolute" else ("‚ö†Ô∏è", st.warning)
        message = f"{icon} **{limit_type}** ‚Üí **{amount or 'N/A'} {currency or ''}** {period}"
        if show_natures:
            nature_names = [nature_lookup.get(nid, f"ID {nid}") for nid in rule.idNatures]
            message += f" pour : **{', '.join(nature_names)}**"
        color_func(message)

    elif isinstance(rule, Allowance):
        thresholds = rule.thresholds[0] if rule.thresholds else Threshold()
        amount, currency = thresholds.amount, rule.currencyCode
        message = f"‚úÖ **Forfait** ‚Üí **{amount or 'N/A'} {currency or ''}**"
        if show_natures:
            nature_names = [nature_lookup.get(nid, f"ID {nid}") for nid in rule.idNatures]
            message += f" pour : **{', '.join(nature_names)}**"
        st.success(message)


# --- G√âN√âRATION DU RAPPORT PDF ---
def _safe_encode(text: str) -> str:
    """Encode le texte en toute s√©curit√© pour la police latin-1 de FPDF."""
    return str(text).encode('latin-1', 'replace').decode('latin-1')

class PDF(FPDF):
    """Classe FPDF personnalis√©e pour g√©n√©rer le rapport PDF."""
    def header(self):
        self.set_font("Helvetica", "B", 12)
        self.cell(0, 10, "Rapport d'analyse de configuration Lucca NDF", new_x=XPos.LMARGIN, new_y=YPos.NEXT, align="C")
        self.ln(5)

    def footer(self):
        self.set_y(-15)
        self.set_font("Helvetica", "I", 8)
        self.cell(0, 10, f"Page {self.page_no()}/{{nb}}", new_x=XPos.RIGHT, new_y=YPos.TOP, align="C")

    def chapter_title(self, title: str):
        self.set_font("Helvetica", "B", 12)
        self.cell(0, 10, title, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align="L")
        self.ln(5)

    def chapter_body(self, df: pd.DataFrame):
        if df.empty:
            self.set_font("Helvetica", "", 10)
            self.multi_cell(0, 10, "Aucune donn√©e √† afficher pour cette section.")
            self.ln()
            return
        
        num_columns = len(df.columns)
        orientation = 'L' if num_columns > 6 else 'P'
        if self.cur_orientation != orientation:
            self.add_page(orientation=orientation)
        
        effective_page_width = self.w - 2 * self.l_margin
        col_width = effective_page_width / num_columns
        
        self.set_font("Helvetica", "B", 8)
        for header in df.columns:
            self.cell(col_width, 10, _safe_encode(header), border=1, align="C")
        self.ln()
        
        self.set_font("Helvetica", "", 8)
        for _, row in df.iterrows():
            for col in df.columns:
                self.cell(col_width, 10, _safe_encode(str(row[col])), border=1)
            self.ln()
        self.ln(10)

def create_pdf_report() -> bytes:
    """G√©n√®re un rapport PDF complet √† partir des donn√©es en session."""
    processed_data = st.session_state.processed_data
    pdf = PDF()
    pdf.alias_nb_pages()
    
    pdf.add_page()
    pdf.chapter_title("Vue d'ensemble des associations Profils/Natures")
    pdf.chapter_body(processed_data["df_profiles"])
    
    pdf.add_page()
    pdf.chapter_title("Analyse comparative des Limites et Indemnites")
    pdf.chapter_body(processed_data["df_limits"])
    
    orphans = find_orphan_nature_ids(processed_data["df_profiles"], processed_data["nature_lookup"])
    if orphans:
        pdf.add_page()
        pdf.chapter_title("Incoherences detectees (natures non trouvees)")
        pdf.set_font("Helvetica", "", 10)
        orphan_text = f"Les ID de natures suivants sont utilises dans des profils mais ne sont pas definis : {sorted(list(orphans))}"
        pdf.multi_cell(0, 10, _safe_encode(orphan_text))
        pdf.ln()

    return bytes(pdf.output())


# --- INTERFACES DES ONGLETS ---
def build_overview_ui():
    """Construit l'interface de l'onglet 'Vue d'Ensemble'."""
    st.header("üìñ Vue d'ensemble des associations Profils/Natures")
    st.write("Utilisez la barre de recherche pour filtrer sur plusieurs mots-cl√©s (ex: `salari√© restaurant`).")
    
    processed_data = st.session_state.processed_data
    df_profiles = processed_data["df_profiles"]
    search_term = st.text_input("üîç Rechercher sur tout le tableau")
    
    display_df = df_profiles
    if search_term:
        with st.spinner("Filtrage des donn√©es..."):
            search_space = display_df.astype(str).apply(' '.join, axis=1).str.lower()
            mask = pd.Series([True] * len(display_df), index=display_df.index)
            for term in search_term.lower().split():
                mask &= search_space.str.contains(term, na=False)
            display_df = display_df[mask]

    if display_df.empty:
        st.warning("Aucun r√©sultat pour cette recherche.")
    else:
        st.dataframe(display_df, use_container_width=True)
        st.divider()
        st.subheader("üöÄ Exports")
        st.write("Les boutons ci-dessous exporteront les donn√©es (le CSV est filtr√©, le PDF et l'Excel sont complets).")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            csv_data = display_df.to_csv(index=False).encode('utf-8')
            st.download_button(label="üì• T√©l√©charger en CSV", data=csv_data, file_name='rapport_profils.csv', mime='text/csv', use_container_width=True)
        with col2:
            pdf_bytes = create_pdf_report()
            st.download_button(label="üìÑ T√©l√©charger en PDF", data=pdf_bytes, file_name="rapport_complet.pdf", mime="application/pdf", use_container_width=True)
        with col3:
            xlsx_output = BytesIO()
            with pd.ExcelWriter(xlsx_output, engine='openpyxl') as writer:
                display_df.to_excel(writer, index=False, sheet_name="Vue d'ensemble (filtree)")
                processed_data['df_limits'].to_excel(writer, index=False, sheet_name="Toutes les regles")
            st.download_button(
                label="üìä T√©l√©charger en Excel (multi-feuilles)", 
                data=xlsx_output.getvalue(), 
                file_name="rapport_complet.xlsx", 
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", 
                use_container_width=True
            )

def build_profile_analysis_ui():
    """Construit l'interface de l'onglet 'Analyse par Profil'."""
    st.header("üë§ Analyse d√©taill√©e par Profil")
    st.write("Choisissez un profil pour afficher en d√©tail sa configuration compl√®te.")
    
    processed_data = st.session_state.processed_data
    data = processed_data["pydantic_data"]
    nature_lookup = processed_data["nature_lookup"]
    
    profiles_dict = {p.name_fr: p for p in data.profiles}
    sorted_profiles = sorted(profiles_dict.keys())
    selected_profil_name = st.selectbox("S√©lectionnez un profil", options=sorted_profiles, key="profile_select_analysis")
    
    if not selected_profil_name: return

    profile = profiles_dict[selected_profil_name]
    st.divider()
    st.subheader(f"D√©tails pour : {selected_profil_name}")

    st.markdown("##### Natures associ√©es")
    nature_names = [nature_lookup.get(nid, f"ID {nid}") for nid in profile.idNatures]
    st.dataframe({"Natures": sorted(nature_names)}, use_container_width=True, hide_index=True)

    st.markdown("##### Limites de D√©penses (Plafonds)")
    if not profile.limits:
        st.info("Aucune limite sp√©cifique n'est d√©finie.")
    else:
        for limit in profile.limits:
            display_rule(limit, nature_lookup)

    st.markdown("##### Indemnit√©s Forfaitaires (Allowances)")
    if not profile.allowances:
        st.info("Aucune indemnit√© forfaitaire n'est d√©finie.")
    else:
        for allowance in profile.allowances:
            display_rule(allowance, nature_lookup)

def build_limits_analysis_ui():
    """Construit l'interface de l'onglet 'Analyse des Limites'."""
    st.header("üìè Analyse comparative des Limites et Indemnit√©s")
    
    df_limits = st.session_state.processed_data["df_limits"]
    if df_limits.empty:
        st.warning("Aucune limite ou indemnit√© n'a √©t√© trouv√©e dans le fichier.")
    else:
        st.subheader("Visualisation du nombre de r√®gles par profil")
        st.write("Ce graphique montre combien de r√®gles (limites + indemnit√©s) sont d√©finies pour chaque profil.")
        rules_per_profile = df_limits["Profil"].value_counts()
        st.bar_chart(rules_per_profile)
        
        st.divider()
        st.subheader("Tableau d√©taill√© des r√®gles")
        st.write("Ce tableau centralise toutes les r√®gles de tous les profils pour faciliter leur comparaison.")
        st.dataframe(df_limits, use_container_width=True)

def build_accounting_plan_ui():
    """Construit l'interface de l'onglet 'Analyse Plan Comptable'."""
    st.header("üßæ Analyse du Plan Comptable par Nature")
    st.write("Choisissez une nature pour voir son imputation comptable dans chaque plan.")
    
    data = st.session_state.processed_data["pydantic_data"]
    if not data.natures:
        st.warning("Aucune nature de d√©pense trouv√©e dans le fichier.")
        return

    natures_list = sorted([(n.name_fr, n.id) for n in data.natures])
    selected_option = st.selectbox(
        "Choisissez une nature √† analyser", 
        options=natures_list, 
        format_func=lambda x: x[0], 
        key="accounting_select"
    )

    if not selected_option: return
    selected_nature_name, selected_nature_id = selected_option
    st.divider()
    
    found = False
    for chart in data.chartsOfAccounts:
        costs_accounts_lookup = {acc.id: acc.value for acc in chart.costsAccounts}
        for mapping in chart.natureAccountMappings:
            if mapping.idNature == selected_nature_id:
                found = True
                with st.expander(f"**Plan : {chart.name}**", expanded=True):
                    compte_de_charge = costs_accounts_lookup.get(mapping.idCostsAccount, 'Non trouv√©')
                    st.markdown(f"**Compte de charge :** `{compte_de_charge}`")
                    st.markdown(f"**ID de TVA applicables :** `{', '.join(map(str, mapping.vat_ids)) or 'Aucun'}`")
    if not found:
        st.warning(f"La nature **{selected_nature_name}** n'est associ√©e √† aucun plan comptable.")

def build_nature_analysis_ui():
    """
    Construit l'interface de l'onglet 'Analyse par Nature'.
    S√©pare les profils avec r√®gles des profils sans r√®gle pour un affichage plus condens√©.
    """
    st.header("üî¨ Analyse d√©taill√©e par Nature")
    st.write("Choisissez une nature pour voir tous les profils et les r√®gles qui s'y appliquent.")

    processed_data = st.session_state.processed_data
    nature_lookup = processed_data["nature_lookup"]
    nature_to_profiles_map = processed_data["nature_to_profiles_map"]

    if not nature_lookup:
        st.warning("Aucune nature de d√©pense √† analyser.")
        return

    natures_list = sorted(nature_lookup.items(), key=lambda item: item[1])
    selected_nature_id = st.selectbox(
        "S√©lectionnez une nature",
        options=[n[0] for n in natures_list],
        format_func=lambda x: nature_lookup.get(x, "N/A"),
        key="nature_select_analysis"
    )
    st.divider()

    if not selected_nature_id: return

    profiles_for_nature = nature_to_profiles_map.get(selected_nature_id, {})
    if not profiles_for_nature:
        st.warning("Aucun profil n'utilise cette nature.")
        return

    st.subheader(f"Analyse pour : {nature_lookup[selected_nature_id]}")

    # --- S√©parer les profils avec et sans r√®gles ---
    profiles_with_rules = {}
    profiles_without_rules = []
    for profile_name, rules in profiles_for_nature.items():
        if rules["limits"] or rules["allowances"]:
            profiles_with_rules[profile_name] = rules
        else:
            profiles_without_rules.append(profile_name)
    
    # --- 1. Afficher les profils AVEC des r√®gles sp√©cifiques ---
    st.markdown("##### Profils avec r√®gles sp√©cifiques")
    if not profiles_with_rules:
        st.info("Aucun profil n'a de r√®gle sp√©cifique pour cette nature.")
    else:
        for profile_name, rules in sorted(profiles_with_rules.items()):
            with st.container(border=True):
                st.markdown(f"**{profile_name}**")
                profile_rules_data = []
                for limit in rules["limits"]:
                    threshold = limit.thresholds[0] if limit.thresholds else Threshold()
                    profile_rules_data.append({
                        "Type": "Limite", "D√©tail": getattr(limit, 'type', 'N/A').capitalize(),
                        "Montant": threshold.amount, "Devise": limit.currencyCode,
                        "P√©riode": PERIOD_TRANSLATION.get(limit.period, limit.period)
                    })
                for allowance in rules["allowances"]:
                    threshold = allowance.thresholds[0] if allowance.thresholds else Threshold()
                    profile_rules_data.append({
                        "Type": "Indemnit√©", "D√©tail": "Forfait", "Montant": threshold.amount,
                        "Devise": allowance.currencyCode, "P√©riode": "N/A"
                    })
                
                df_profile_rules = pd.DataFrame(profile_rules_data)
                st.dataframe(df_profile_rules, hide_index=True, use_container_width=True)
    
    st.divider()

    # --- 2. Afficher les profils SANS r√®gles sp√©cifiques ---
    st.markdown("##### Profils utilisant cette nature sans r√®gle sp√©cifique")
    if not profiles_without_rules:
        st.info("Tous les profils utilisant cette nature ont des r√®gles sp√©cifiques.")
    else:
        df_no_rules = pd.DataFrame(sorted(profiles_without_rules), columns=["Profil"])
        st.dataframe(df_no_rules, hide_index=True, use_container_width=True)


def build_comparison_ui():
    """Construit l'interface du comparateur de profils avec une analyse des diff√©rences."""
    st.header("‚öñÔ∏è Comparateur de Profils")
    st.write("S√©lectionnez deux profils pour afficher une analyse comparative d√©taill√©e de leurs configurations.")
    
    processed_data = st.session_state.processed_data
    df_profiles = processed_data["df_profiles"]
    df_limits = processed_data["df_limits"]
    
    all_profiles = sorted(df_profiles["Profil"].unique())
    selected_profiles = st.multiselect("Choisissez les profils √† comparer", options=all_profiles, max_selections=2)

    if len(selected_profiles) != 2:
        st.info("Veuillez s√©lectionner exactement deux profils pour lancer la comparaison.")
        return
        
    st.divider()
    profile1_name, profile2_name = selected_profiles[0], selected_profiles[1]
    st.subheader(f"Comparaison : `{profile1_name}` vs `{profile2_name}`")

    # --- 1. Comparaison des Natures ---
    with st.expander("üïµÔ∏è **Analyse des Natures**", expanded=True):
        natures1 = set(df_profiles[df_profiles["Profil"] == profile1_name]["Nom de la nature"])
        natures2 = set(df_profiles[df_profiles["Profil"] == profile2_name]["Nom de la nature"])

        common_natures = sorted(list(natures1 & natures2))
        unique_to_1 = sorted(list(natures1 - natures2))
        unique_to_2 = sorted(list(natures2 - natures1))

        st.markdown("##### ‚úÖ Natures Communes")
        if common_natures:
            st.dataframe({"Natures partag√©es": common_natures}, use_container_width=True, hide_index=True)
        else:
            st.info("Aucune nature en commun.")

        st.markdown("##### üîç Natures Uniques")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f"**Uniques √† `{profile1_name}`**")
            if unique_to_1:
                st.dataframe({f"Natures uniques ({len(unique_to_1)})": unique_to_1}, hide_index=True, use_container_width=True)
            else:
                st.info("Aucune.")
        with col2:
            st.markdown(f"**Uniques √† `{profile2_name}`**")
            if unique_to_2:
                st.dataframe({f"Natures uniques ({len(unique_to_2)})": unique_to_2}, hide_index=True, use_container_width=True)
            else:
                st.info("Aucune.")
    
    # --- 2. Comparaison des R√®gles ---
    with st.expander("üìè **Analyse des R√®gles (Limites et Indemnit√©s)**", expanded=True):
        rules1 = df_limits[df_limits["Profil"] == profile1_name].drop(columns='Profil')
        rules2 = df_limits[df_limits["Profil"] == profile2_name].drop(columns='Profil')

        if rules1.empty and rules2.empty:
            st.info("Aucun des deux profils n'a de r√®gle sp√©cifique.")
        else:
            comparison_df = pd.merge(
                rules1, rules2, 
                on=["Natures Concern√©es", "Type de R√®gle"], 
                how='outer', 
                suffixes=(f' ({profile1_name})', f' ({profile2_name})')
            )
            st.write("Ce tableau fusionne les r√®gles. Les `NaN` indiquent une r√®gle absente pour un profil.")
            st.dataframe(comparison_df, use_container_width=True, hide_index=True)


# --- POINT D'ENTR√âE PRINCIPAL ---
def main():
    """Point d'entr√©e principal de l'application Streamlit."""
    st.title("üìä Analyseur de configuration Lucca NDF")
    st.info(
        "üëã **Bienvenue !** Cet outil vous permet d'analyser et d'auditer vos profils de d√©penses."
        " Chargez votre fichier `Full.json` ci-dessous pour commencer."
    )

    uploaded_file = st.file_uploader("D√©posez votre fichier `Full.json` ici", type="json")

    if uploaded_file:
        # On ne retraite le fichier que s'il est nouveau pour optimiser
        if 'processed_data' not in st.session_state or st.session_state.get('uploaded_filename') != uploaded_file.name:
            st.session_state.processed_data = load_and_process_data(uploaded_file)
            st.session_state.uploaded_filename = uploaded_file.name

        processed_data = st.session_state.processed_data
        
        if processed_data and processed_data.get("error") is None:
            st.toast("Fichier valid√© et trait√© avec succ√®s !", icon="‚úÖ")
            
            pydantic_data = processed_data["pydantic_data"]
            df_profiles = processed_data["df_profiles"]
            nature_lookup = processed_data["nature_lookup"]

            orphans = find_orphan_nature_ids(df_profiles, nature_lookup)
            if orphans:
                with st.expander("üö© Incoh√©rences d√©tect√©es (natures non trouv√©es)", expanded=False):
                    st.warning(f"Les ID suivants sont pr√©sents dans des profils mais absents de la table des natures : {sorted(list(orphans))}")

            inconsistencies = audit_inconsistent_rules(pydantic_data, nature_lookup)
            if inconsistencies:
                with st.expander("‚ö†Ô∏è Alertes de configuration (r√®gles √† 0 ou sans montant)", expanded=True):
                    for warning_text in inconsistencies:
                        st.warning(warning_text)

            tabs_titles = [
                "üìñ Vue d'Ensemble", "üë§ Analyse par Profil", "üî¨ Analyse par Nature",
                "üìè Analyse des Limites", "üßæ Analyse Plan Comptable", "‚öñÔ∏è Comparateur de Profils"
            ]
            tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(tabs_titles)

            with tab1: build_overview_ui()
            with tab2: build_profile_analysis_ui()
            with tab3: build_nature_analysis_ui()
            with tab4: build_limits_analysis_ui()
            with tab5: build_accounting_plan_ui()
            with tab6: build_comparison_ui()

if __name__ == "__main__":
    main()