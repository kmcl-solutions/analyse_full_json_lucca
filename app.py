# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import json
from fpdf import FPDF
from fpdf.enums import XPos, YPos
import io
from io import BytesIO
import traceback
from pydantic import BaseModel, Field, ValidationError
from typing import List, Optional

# --- CONFIGURATION & CONSTANTES ---
st.set_page_config(page_title="Rapports Cleemy", layout="wide")

PERIOD_TRANSLATION = {"Day": "par Jour", "None": "par D√©pense", "Month": "par Mois", "Year": "par An"}

class JsonKeys:
    PROFILES = "profiles"
    NATURES = "natures"
    LIMITS = "limits"
    ALLOWANCES = "allowances"
    ID = "id"
    ID_NATURES = "idNatures"
    MULTILINGUAL_NAME = "multilingualName"
    CURRENCY_CODE = "currencyCode"
    THRESHOLDS = "thresholds"
    AMOUNT = "amount"
    TYPE = "type"
    PERIOD = "period"
    CHARTS_OF_ACCOUNTS = "chartsOfAccounts"
    COSTS_ACCOUNTS = "costsAccounts"
    FORMAT = "format"
    VALUE = "value"
    NAME = "name"
    NATURE_ACCOUNT_MAPPINGS = "natureAccountMappings"
    ID_NATURE = "idNature"
    ID_COSTS_ACCOUNT = "idCostsAccount"
    VAT_OPTIONS = "vatOptions"
    ID_COUNTRY_VATS = "idCountryVats"
    FR_FR = "fr-FR"


# --- MOD√àLES PYDANTIC ---
class Threshold(BaseModel):
    amount: Optional[float] = None

class Limit(BaseModel):
    idNatures: List[int] = Field(default_factory=list)
    type: Optional[str] = None
    period: Optional[str] = None
    currencyCode: Optional[str] = None
    thresholds: List[Threshold] = Field(default_factory=list)

class Allowance(BaseModel):
    idNatures: List[int] = Field(default_factory=list)
    currencyCode: Optional[str] = None
    thresholds: List[Threshold] = Field(default_factory=list)

class Profile(BaseModel):
    id: Optional[int] = None
    multilingualName: dict = Field(default_factory=dict)
    idNatures: List[int] = Field(default_factory=list)
    limits: List[Limit] = Field(default_factory=list)
    allowances: List[Allowance] = Field(default_factory=list)
    
    @property
    def name_fr(self) -> str:
        name = self.multilingualName.get(JsonKeys.FR_FR)
        if name:
            return name
        if self.id is not None:
            return f"Profil sans nom (ID: {self.id})"
        return "Profil non identifi√©"

class Nature(BaseModel):
    id: int
    multilingualName: dict = Field(default_factory=dict)
    
    @property
    def name_fr(self) -> str:
        return self.multilingualName.get(JsonKeys.FR_FR, f"ID {self.id}")

class CostsAccount(BaseModel):
    id: int
    format: List[dict] = Field(default_factory=list)
    
    @property
    def value(self) -> str:
        return self.format[0].get(JsonKeys.VALUE, 'N/A') if self.format else 'N/A'

class NatureAccountMapping(BaseModel):
    idNature: int
    idCostsAccount: Optional[int] = None
    vatOptions: dict = Field(default_factory=dict)
    
    @property
    def vat_ids(self) -> List[str]:
        return self.vatOptions.get(JsonKeys.ID_COUNTRY_VATS, [])

class ChartOfAccounts(BaseModel):
    id: int
    name: Optional[str] = None
    costsAccounts: List[CostsAccount] = Field(default_factory=list)
    natureAccountMappings: List[NatureAccountMapping] = Field(default_factory=list)

class CleemyData(BaseModel):
    profiles: List[Profile] = Field(default_factory=list)
    natures: List[Nature] = Field(default_factory=list)
    chartsOfAccounts: List[ChartOfAccounts] = Field(default_factory=list)


# --- FONCTIONS DE TRAITEMENT ET D'AUDIT DES DONN√âES ---
@st.cache_data(hash_funcs={BytesIO: lambda _: None})
def load_and_process_data(uploaded_file: io.BytesIO) -> dict | None:
    """Charge, valide avec Pydantic et pr√©-traite les donn√©es JSON."""
    with st.spinner("Analyse et validation du fichier en cours..."):
        try:
            uploaded_file.seek(0)
            raw_data = json.load(uploaded_file)
            data = CleemyData.parse_obj(raw_data)

            nature_lookup = {n.id: n.name_fr for n in data.natures}
            df_profiles = _create_profile_nature_df(data, nature_lookup)
            df_limits = _create_limits_df(data, nature_lookup)
            nature_to_profiles_map = _create_nature_to_profiles_map(data)

            return {
                "pydantic_data": data,
                "nature_lookup": nature_lookup,
                "df_profiles": df_profiles,
                "df_limits": df_limits,
                "nature_to_profiles_map": nature_to_profiles_map,
                "error": None
            }
        except ValidationError as e:
            st.error(f"‚ùå Fichier invalide : la structure des donn√©es est incorrecte.")
            st.code(str(e))
            return {"error": str(e)}
        except Exception as e:
            st.error(f"Une erreur critique est survenue : {e}")
            return {"error": traceback.format_exc()}

def _create_profile_nature_df(data: CleemyData, nature_lookup: dict) -> pd.DataFrame:
    export_data = []
    for profile in data.profiles:
        for id_nature in profile.idNatures:
            export_data.append({
                "Profil": profile.name_fr,
                "ID Nature": id_nature,
                "Nom de la nature": nature_lookup.get(id_nature, "‚ùì Inconnu"),
            })
    return pd.DataFrame(export_data)

def _create_limits_df(data: CleemyData, nature_lookup: dict) -> pd.DataFrame:
    limits_data = []
    for profile in data.profiles:
        profile_name = profile.name_fr
        for limit in profile.limits:
            nature_names = [nature_lookup.get(nid, f"ID {nid}") for nid in limit.idNatures]
            thresholds = limit.thresholds[0] if limit.thresholds else Threshold()
            limits_data.append({
                "Profil": profile_name, "Type de R√®gle": "Limite",
                "Natures Concern√©es": ", ".join(filter(None, nature_names)),
                "Type de Plafond": getattr(limit, 'type', 'N/A').capitalize(),
                "Montant": thresholds.amount,
                "Devise": limit.currencyCode,
                "P√©riode": PERIOD_TRANSLATION.get(limit.period, limit.period)
            })
        for allowance in profile.allowances:
            nature_names = [nature_lookup.get(nid, f"ID {nid}") for nid in allowance.idNatures]
            thresholds = allowance.thresholds[0] if allowance.thresholds else Threshold()
            limits_data.append({
                "Profil": profile_name, "Type de R√®gle": "Indemnit√©",
                "Natures Concern√©es": ", ".join(filter(None, nature_names)),
                "Type de Plafond": "Forfait",
                "Montant": thresholds.amount,
                "Devise": allowance.currencyCode, "P√©riode": "N/A"
            })
    return pd.DataFrame(limits_data)

def _create_nature_to_profiles_map(data: CleemyData) -> dict:
    nature_map = {}
    for profile in data.profiles:
        for nature_id in profile.idNatures:
            nature_map.setdefault(nature_id, {}).setdefault(profile.name_fr, {"limits": [], "allowances": []})
        for limit in profile.limits:
            for nature_id in limit.idNatures:
                profile_rules = nature_map.setdefault(nature_id, {}).setdefault(profile.name_fr, {"limits": [], "allowances": []})
                profile_rules["limits"].append(limit)
        for allowance in profile.allowances:
            for nature_id in allowance.idNatures:
                profile_rules = nature_map.setdefault(nature_id, {}).setdefault(profile.name_fr, {"limits": [], "allowances": []})
                profile_rules["allowances"].append(allowance)
    return nature_map

def find_orphan_nature_ids(df_profiles, nature_lookup):
    """Trouve les ID de natures utilis√©s dans les profils mais non d√©finis."""
    nature_ids_in_df = set(df_profiles["ID Nature"].unique())
    nature_ids_in_dict = set(nature_lookup.keys())
    orphans = nature_ids_in_df - nature_ids_in_dict
    return orphans

# --- G√âN√âRATION DU RAPPORT PDF ---
def create_pdf_report(df: pd.DataFrame) -> bytes:
    """G√©n√®re un rapport PDF, en mode paysage si le tableau est trop large."""
    num_columns = len(df.columns)
    orientation = 'L' if num_columns > 7 else 'P'
    
    pdf = FPDF(orientation=orientation)
    pdf.add_page()
    pdf.set_font("Helvetica", 'B', size=12)
    pdf.cell(0, 10, "Rapport d'analyse Cleemy", new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='C')
    pdf.ln(10)
    
    effective_page_width = pdf.w - 2 * pdf.l_margin
    col_width = effective_page_width / num_columns if num_columns > 0 else effective_page_width

    pdf.set_font("Helvetica", 'B', size=8)
    for header in df.columns:
        safe_header = str(header).encode('latin-1', 'replace').decode('latin-1')
        pdf.cell(col_width, 10, safe_header, border=1, align='C')
    pdf.ln()

    pdf.set_font("Helvetica", '', size=8)
    for _, row in df.iterrows():
        for col in df.columns:
            safe_text = str(row[col]).encode('latin-1', 'replace').decode('latin-1')
            pdf.cell(col_width, 10, safe_text, border=1)
        pdf.ln()
        
    return bytes(pdf.output())


# --- INTERFACES DES ONGLETS ---
def build_overview_ui(df_profiles: pd.DataFrame):
    """Affiche l'onglet Vue d'ensemble avec recherche multi-mots-cl√©s."""
    st.header("üìñ Vue d'ensemble des associations Profils/Natures")
    st.write("Utilisez la barre de recherche pour filtrer sur plusieurs mots-cl√©s (ex: `salari√© restaurant`).")
    search_term = st.text_input("üîç Rechercher sur tout le tableau")
    
    display_df = df_profiles
    if search_term:
        with st.spinner("Filtrage des donn√©es..."):
            search_terms = search_term.lower().split()
            mask = display_df.apply(
                lambda row: all(term in str(row).lower() for term in search_terms),
                axis=1
            )
            display_df = display_df[mask]

    if display_df.empty:
        st.warning("Aucun r√©sultat pour cette recherche.")
    else:
        st.dataframe(display_df, use_container_width=True)
        st.divider()
        st.subheader("üöÄ Exports")
        st.write("Les boutons ci-dessous exporteront les donn√©es actuellement affich√©es (filtr√©es ou non).")
        col1, col2, col3 = st.columns(3)
        with col1:
            csv_data = display_df.to_csv(index=False).encode('utf-8')
            st.download_button(label="üì• T√©l√©charger en CSV", data=csv_data, file_name='rapport_profils.csv', mime='text/csv', use_container_width=True)
        with col2:
            pdf_bytes = create_pdf_report(display_df)
            st.download_button(label="üìÑ T√©l√©charger en PDF", data=pdf_bytes, file_name="rapport_profils.pdf", mime="application/pdf", use_container_width=True)
        with col3:
            xlsx_output = BytesIO()
            with pd.ExcelWriter(xlsx_output, engine='openpyxl') as writer:
                display_df.to_excel(writer, index=False, sheet_name='Rapport')
            st.download_button(label="üìä T√©l√©charger en Excel", data=xlsx_output.getvalue(), file_name="rapport_profils.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)

def build_profile_analysis_ui(data: CleemyData, nature_lookup: dict):
    st.header("üë§ Analyse d√©taill√©e par Profil")
    st.write("Choisissez un profil pour afficher en d√©tail sa configuration compl√®te.")
    
    profiles_dict = {p.name_fr: p for p in data.profiles}
    sorted_profiles = sorted(profiles_dict.keys())
    selected_profil_name = st.selectbox("S√©lectionnez un profil", options=sorted_profiles, key="profile_select_analysis")
    
    if not selected_profil_name: return

    profile = profiles_dict[selected_profil_name]
    st.divider()
    st.subheader(f"D√©tails pour : {selected_profil_name}")

    st.markdown("##### Natures associ√©es")
    nature_names = [nature_lookup.get(nid, f"ID {nid}") for nid in profile.idNatures]
    st.dataframe({"Natures": sorted(nature_names)}, use_container_width=True, hide_index=True)

    st.markdown("##### Limites de D√©penses (Plafonds)")
    if not profile.limits:
        st.info("Aucune limite sp√©cifique n'est d√©finie.")
    else:
        for limit in profile.limits:
            thresholds = limit.thresholds[0] if limit.thresholds else Threshold()
            amount, currency = thresholds.amount, limit.currencyCode
            limit_type, period = getattr(limit, 'type', 'N/A').capitalize(), limit.period
            nature_names_limit = [nature_lookup.get(nid, f"ID {nid}") for nid in limit.idNatures]
            prefix = "üõë" if limit_type == "Absolute" else "‚ö†Ô∏è"
            message = f"{prefix} **{limit_type}** ‚Üí **{amount} {currency or ''}** {PERIOD_TRANSLATION.get(period, period)} pour : **{', '.join(filter(None, nature_names_limit))}**"
            st.markdown(message)

    st.markdown("##### Indemnit√©s Forfaitaires (Allowances)")
    if not profile.allowances:
        st.info("Aucune indemnit√© forfaitaire n'est d√©finie.")
    else:
        for allowance in profile.allowances:
            thresholds = allowance.thresholds[0] if allowance.thresholds else Threshold()
            amount, currency = thresholds.amount, allowance.currencyCode
            nature_names_allowance = [nature_lookup.get(nid, f"ID {nid}") for nid in allowance.idNatures]
            message = f"‚úÖ **Forfait** ‚Üí **{amount} {currency or ''}** pour : **{', '.join(filter(None, nature_names_allowance))}**"
            st.markdown(message)

def build_limits_analysis_ui(df_limits: pd.DataFrame):
    st.header("üìè Analyse comparative des Limites et Indemnit√©s")
    if df_limits.empty:
        st.warning("Aucune limite ou indemnit√© n'a √©t√© trouv√©e dans le fichier.")
    else:
        st.subheader("Visualisation du nombre de r√®gles par profil")
        st.write("Ce graphique montre combien de r√®gles (limites + indemnit√©s) sont d√©finies pour chaque profil.")
        rules_per_profile = df_limits["Profil"].value_counts()
        st.bar_chart(rules_per_profile)
        
        st.divider()
        st.subheader("Tableau d√©taill√© des r√®gles")
        st.write("Ce tableau centralise toutes les r√®gles de tous les profils pour faciliter leur comparaison.")
        st.dataframe(df_limits, use_container_width=True)

def build_accounting_plan_ui(data: CleemyData):
    st.header("üßæ Analyse du Plan Comptable par Nature")
    st.write("Choisissez une nature pour voir son imputation comptable dans chaque plan.")
    
    if not data.natures:
        st.warning("Aucune nature de d√©pense trouv√©e dans le fichier.")
        return

    natures_list = sorted([(n.name_fr, n.id) for n in data.natures])
    
    selected_option = st.selectbox(
        "Choisissez une nature √† analyser", 
        options=natures_list, 
        format_func=lambda x: x[0], 
        key="accounting_select"
    )

    if not selected_option:
        return

    selected_nature_name, selected_nature_id = selected_option
    st.divider()
    
    found = False
    for chart in data.chartsOfAccounts:
        costs_accounts_lookup = {acc.id: acc.value for acc in chart.costsAccounts}
        for mapping in chart.natureAccountMappings:
            if mapping.idNature == selected_nature_id:
                found = True
                with st.expander(f"**Plan : {chart.name}**", expanded=True):
                    compte_de_charge = costs_accounts_lookup.get(mapping.idCostsAccount, 'Non trouv√©')
                    st.markdown(f"**Compte de charge :** `{compte_de_charge}`")
                    st.markdown(f"**ID de TVA applicables :** `{', '.join(map(str, mapping.vat_ids)) or 'Aucun'}`")
    if not found:
        st.warning(f"La nature **{selected_nature_name}** n'est associ√©e √† aucun plan comptable.")

def build_nature_analysis_ui(nature_lookup: dict, nature_to_profiles_map: dict):
    st.header("üî¨ Analyse d√©taill√©e par Nature")
    st.write("Choisissez une nature pour voir tous les profils et les r√®gles qui s'y appliquent.")
    
    if not nature_lookup:
        st.warning("Aucune nature de d√©pense √† analyser.")
        return

    natures_list = sorted(nature_lookup.items(), key=lambda item: item[1])
    selected_nature_id = st.selectbox(
        "S√©lectionnez une nature",
        options=[n[0] for n in natures_list],
        format_func=lambda x: nature_lookup.get(x, "N/A"),
        key="nature_select_analysis"
    )
    st.divider()

    if not selected_nature_id: return
    profiles_for_nature = nature_to_profiles_map.get(selected_nature_id, {})
    if not profiles_for_nature:
        st.warning("Aucun profil n'utilise cette nature.")
        return

    st.subheader(f"Profils et r√®gles pour : {nature_lookup[selected_nature_id]}")
    for profile_name, rules in sorted(profiles_for_nature.items()):
        with st.container(border=True):
            st.markdown(f"#### Profil : {profile_name}")
            if not rules["limits"] and not rules["allowances"]:
                st.info("Ce profil utilise cette nature sans limite ni indemnit√© sp√©cifique.")
            if rules["limits"]:
                st.markdown("###### Limites (Plafonds)")
                for limit in rules["limits"]:
                    thresholds = limit.thresholds[0] if limit.thresholds else Threshold()
                    amount, currency = thresholds.amount, limit.currencyCode
                    limit_type, period = getattr(limit, 'type', 'N/A').capitalize(), limit.period
                    message = f"**{limit_type}** ‚Üí **{amount} {currency or ''}** {PERIOD_TRANSLATION.get(period, period)}"
                    st.error(f"üõë {message}") if limit_type == "Absolute" else st.warning(f"‚ö†Ô∏è {message}")
            if rules["allowances"]:
                st.markdown("###### Indemnit√©s (Forfaits)")
                for allowance in rules["allowances"]:
                    thresholds = allowance.thresholds[0] if allowance.thresholds else Threshold()
                    amount, currency = thresholds.amount, allowance.currencyCode
                    st.success(f"‚úÖ **Forfait** ‚Üí **{amount} {currency or ''}**")

def build_comparison_ui(df_profiles: pd.DataFrame, df_limits: pd.DataFrame):
    st.header("‚öñÔ∏è Comparateur de Profils")
    st.write("S√©lectionnez deux profils ou plus pour afficher leurs configurations c√¥te √† c√¥te.")
    all_profiles = sorted(df_profiles["Profil"].unique())
    selected_profiles = st.multiselect("Choisissez les profils √† comparer", options=all_profiles)

    if len(selected_profiles) > 1:
        st.divider()
        cols = st.columns(len(selected_profiles))
        for i, profile_name in enumerate(selected_profiles):
            with cols[i]:
                st.subheader(profile_name)
                st.markdown("**Natures associ√©es :**")
                natures_for_profile = df_profiles[df_profiles["Profil"] == profile_name]["Nom de la nature"]
                st.dataframe(natures_for_profile, hide_index=True, use_container_width=True)
                st.markdown("**R√®gles d√©finies :**")
                rules_for_profile = df_limits[df_limits["Profil"] == profile_name]
                if rules_for_profile.empty:
                    st.info("Aucune r√®gle sp√©cifique.")
                else:
                    st.dataframe(rules_for_profile.drop(columns=['Profil']), hide_index=True, use_container_width=True)
    elif len(selected_profiles) == 1:
        st.info("Veuillez s√©lectionner au moins deux profils pour les comparer.")


# --- POINT D'ENTR√âE PRINCIPAL ---
def main():
    st.title("üìä Rapports d'analyse Lucca Notes de Frais / Cleemy")
    st.info("Version optimis√©e avec validation Pydantic, cache s√©curis√©, PDF dynamique et recherche avanc√©e.")
    uploaded_file = st.file_uploader("D√©posez votre fichier `Full.json` ici", type="json")

    if uploaded_file:
        processed_data = load_and_process_data(uploaded_file)
        
        if processed_data and processed_data.get("error") is None:
            st.toast("Fichier valid√© et trait√© avec succ√®s !", icon="‚úÖ")
            
            # Audit des natures orphelines
            orphans = find_orphan_nature_ids(processed_data["df_profiles"], processed_data["nature_lookup"])
            if orphans:
                with st.expander("üö© Incoh√©rences d√©tect√©es (natures non trouv√©es)", expanded=False):
                    st.warning(f"Les ID suivants sont pr√©sents dans des profils mais absents de la table des natures : {sorted(list(orphans))}")

            tabs_titles = [
                "üìñ Vue d'Ensemble", "üë§ Analyse par Profil", "üî¨ Analyse par Nature",
                "üìè Analyse des Limites", "üßæ Analyse Plan Comptable", "‚öñÔ∏è Comparateur de Profils"
            ]
            tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(tabs_titles)

            with tab1:
                build_overview_ui(processed_data["df_profiles"])
            with tab2:
                build_profile_analysis_ui(processed_data["pydantic_data"], processed_data["nature_lookup"])
            with tab3:
                build_nature_analysis_ui(processed_data["nature_lookup"], processed_data["nature_to_profiles_map"])
            with tab4:
                build_limits_analysis_ui(processed_data["df_limits"])
            with tab5:
                build_accounting_plan_ui(processed_data["pydantic_data"])
            with tab6:
                build_comparison_ui(processed_data["df_profiles"], processed_data["df_limits"])

if __name__ == "__main__":
    main()